{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">回顾&引言\\\n",
    "前面一章的内容大家可以感觉到我们主要是对基础知识做一个梳理，让大家了解数据分析的一些操作，主要做了数据的各个角度的观察。那么在这里，我们主要是做数据分析的流程性学习，主要是包括了数据清洗以及数据的特征处理，数据重构以及数据可视化。这些内容是为数据分析最后的建模和模型评价做一个铺垫。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 第二章：数据清洗及特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始之前，导入numpy、pandas包和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载所需的库\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据train.csv\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清洗简述\n",
    "我们拿到的数据通常是不干净的，所谓的不干净，就是数据中有缺失值，有一些异常点等，需要经过一定的处理才能继续做后面的分析或建模，所以拿到数据的第一步是进行数据清洗，本章我们将学习缺失值、重复值、字符串和数据转换等操作，将数据清洗成可以分析或建模的样子。\n",
    "\n",
    "### 2.1 缺失值观察与处理\n",
    "我们拿到的数据经常会有很多缺失值，比如我们可以看到Cabin列存在NaN，那其他列还有没有缺失值，这些缺失值要怎么处理呢\n",
    "\n",
    "#### 2.1.1 任务一：缺失值观察\n",
    "(1) 请查看每个特征缺失值个数  \n",
    "(2) 请查看Age， Cabin， Embarked列的数据\n",
    "以上方式都有多种方式，所以建议大家学习的时候多多益善"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法一\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#方法二\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['Age','Cabin','Embarked']].head(6)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 任务二：对缺失值进行处理\n",
    "(1)处理缺失值一般有几种思路\n",
    "\n",
    "(2) 请尝试对Age列的数据的缺失值进行处理\n",
    "\n",
    "(3) 请尝试使用不同的方法直接对整张表的缺失值进行处理  \n",
    "\n",
    "\n",
    "以下是举例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Age']==None]=0\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Age'].isnull()] = 0 # 这会使 age 属性为空的行整行变成 0\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Age'] == np.nan] = 0  # 似乎没用??\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【思考】检索空缺值用np.nan要比用None好，这是为什么？\n",
    "\n",
    "【回答】数值列读取数据后，空缺值的数据类型为float64所以用None一般索引不到，比较的时候最好用np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # dropna()会drop掉任何含有nan属性的条目,(直接使条目数骤降) 并且注意是否启用参数 inplace\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.fillna(0).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【思考】dropna和fillna有哪些参数，分别如何使用呢?  \n",
    "\n",
    "【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "\n",
    "【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 重复值观察与处理\n",
    "由于这样那样的原因，数据中会不会存在重复值呢，如果存在要怎样处理呢\n",
    "\n",
    "#### 2.2.1 任务一：请查看数据中的重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 任务二：对重复值进行处理\n",
    "(1)重复值有哪些处理方式呢？\n",
    "\n",
    "(2)处理我们数据的重复值\n",
    "\n",
    "方法多多益善"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是对整个行有 ~~缺失值~~ 重复值的清理的方法举例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.info()  # 清洗之前是891个条目, 占用83.6kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.2.3 任务三：将前面清洗的数据保存为csv格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_clear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 特征观察与处理\n",
    "我们对特征进行一下观察，可以把特征大概分为两大类：  \n",
    "\n",
    "数值型特征：Survived ，Pclass， Age ，SibSp， Parch， Fare，其中Survived， Pclass为离散型数值特征，Age，SibSp， Parch， Fare为连续型数值特征\n",
    "\n",
    "文本型特征：Name， Sex， Cabin，Embarked， Ticket，其中Sex， Cabin， Embarked， Ticket为类别型文本特征。\n",
    "\n",
    "数值型特征一般可以直接用于模型的训练，但有时候为了模型的稳定性及鲁棒性会对连续变量进行离散化。文本型特征往往需要转换成数值型特征才能用于建模分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 任务一：对年龄进行分箱（离散化）处理\n",
    "(1) 分箱操作是什么？\n",
    "\n",
    "(2) 将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示  \n",
    "\n",
    "(3) 将连续变量Age划分为[0,5) [5,15) [15,30) [30,50) [50,80)五个年龄段，并分别用类别变量12345表示  \n",
    "\n",
    "(4) 将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示\n",
    "\n",
    "(5) 将上面的获得的数据分别进行保存，保存为csv格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示\n",
    "df['AgeBand'] = pd.cut(df['Age'], 5,labels = ['1','2','3','4','5'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_ave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将连续变量Age划分为[0,5) [5,15) [15,30) [30,50) [50,80)五个年龄段，并分别用类别变量12345表示\n",
    "df['AgeBand'] = pd.cut(df['Age'],[0,5,15,30,50,80],labels = ['1','2','3','4','5'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_cut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示\n",
    "df['AgeBand'] = pd.qcut(df['Age'],[0,0.1,0.3,0.5,0.7,0.9],labels = ['1','2','3','4','5'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_pr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 任务二：对文本变量进行转换\n",
    "(1) 查看文本变量名及种类  \n",
    "(2) 将文本变量Sex， Cabin ，Embarked用数值变量12345表示  \n",
    "(3) 将文本变量Sex， Cabin， Embarked用one-hot编码表示\n",
    "\n",
    "方法多多益善"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看类别文本变量名及种类\n",
    "\n",
    "#方法一: value_counts\n",
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法二: unique\n",
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将类别文本转换为12345\n",
    "\n",
    "#方法一: replace\n",
    "df['Sex_num'] = df['Sex'].replace(['male','female'],[1,2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法二: map\n",
    "df['Sex_num'] = df['Sex'].map({'male': 1, 'female': 2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法三: 使用sklearn.preprocessing的LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for feat in ['Cabin', 'Ticket']:\n",
    "    lbl = LabelEncoder()  \n",
    "    label_dict = dict(zip(df[feat].unique(), range(df[feat].nunique())))  # 这句绝妙啊\n",
    "    df[feat + \"_labelEncode\"] = df[feat].map(label_dict)  # *\n",
    "    df[feat + \"_labelEncode\"] = lbl.fit_transform(df[feat].astype(str))  # 与第6行作用一样\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "dddf = pd.DataFrame(data=dd)\n",
    "dddf['col2'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df[feat].astype(str)\n",
    "```\n",
    "df[feat].astype(str)\n",
    "```\n",
    "astype(dtype) 的作用就是把原数据类型转换成dtype, 方法3例子中把转换成str型\n",
    "\n",
    "#### LabelEncoder.fit_transform()\n",
    "```\n",
    "df[feat + \"_labelEncode\"] = lbl.fit_transform(df[feat].astype(str))\n",
    "```\n",
    "lbl.fit_transform() 的作用就是先根据参数的unique进行映射规则的构建(fit), 再把参数中的目标数据带入映射得到结果(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#将类别文本转换为one-hot编码\n",
    "\n",
    "#方法一: OneHotEncoder\n",
    "for feat in [\"Age\", \"Embarked\"]:\n",
    "#     x = pd.get_dummies(df[\"Age\"] // 6)\n",
    "#     x = pd.get_dummies(pd.cut(df['Age'],5))\n",
    "    x = pd.get_dummies(df[feat], prefix=feat)\n",
    "    df = pd.concat([df, x], axis=1)\n",
    "    #df[feat] = pd.get_dummies(df[feat], prefix=feat)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 独热编码 (one-hot Encoding) 解释\n",
    "如果使用 \\[0, 1, 2\\] 这种方式映射特征的类别, 则引入了额外的关系（例如数值间的大小关系），“误导”模型的优化方向。一个更好的方式就是使用独热(哑)编码, 但用独热编码导致的一个结果就是数据会变得非常的稀疏。\n",
    "\n",
    "例子\n",
    "```\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([\n",
    "    [0, 2, 1, 12],\n",
    "    [1, 3, 5, 3],\n",
    "    [2, 3, 2, 12],\n",
    "    [1, 2, 4, 3]\n",
    "])\n",
    "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
    "print(\"\\n Encoded vector =\", encoded_vector)\n",
    "```\n",
    "输出:\n",
    "```\n",
    ">>Encoded vector = [[ 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]\n",
    "```\n",
    "\n",
    "4个特征：\n",
    "第一个特征（即为第一列）为[0,1,2,1] ，其中三类特征值[0,1,2]，因此One-Hot Code可将[0,1,2]表示为:[100,010,001]\n",
    "同理第二个特征列可将两类特征值[2,3]表示为[10,01]\n",
    "第三个特征将4类特征值[1,2,4,5]表示为[1000,0100,0010,0001]\n",
    "第四个特征将2类特征值[3,12]表示为[10,01]\n",
    "\n",
    "因此最后可将[2,3,5,3]表示为[0,0,1,0,1,0,0,0,1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 任务三(附加): 从纯文本Name特征里提取出Titles的特征(所谓的Titles就是Mr,Miss,Mrs等)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存上面的为最终结论\n",
    "df.to_csv('test_fin.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "433px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
